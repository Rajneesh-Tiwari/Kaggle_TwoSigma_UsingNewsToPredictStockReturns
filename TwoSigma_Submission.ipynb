{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d655bcdb3cdacfd754fecee7d27fbae8859a5bda"
      },
      "cell_type": "code",
      "source": "\"\"\"\nThis is a template for the APIs of models to be used into the stacking framework.\nrun with Python 3.x\n\"\"\"\nfrom time import time, ctime\nimport lightgbm as lgb\nimport pandas as pd\nimport numpy as np\nimport pickle as pk\nfrom matplotlib import pyplot as plt\nfrom pathos.multiprocessing import ProcessingPool as Pool\nfrom datetime import datetime, date\nimport shap\nimport sys\nimport os\n\n\ndef sigma_score(preds, valid_data):\n    \"\"\"\n    this is a custom metric used to train the model_lgbm_baseline\n    \"\"\"\n    df_time = valid_data.params['extra_time'] # will be injected afterwards\n    labels = valid_data.get_label()\n\n    #    assert len(labels) == len(df_time)\n\n    x_t = preds * labels #  * df_valid['universe'] -> Here we take out the 'universe' term because we already keep only those equals to 1.\n\n    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n    # is a pd.Series and call `group_by`\n    x_t_sum = x_t.groupby(df_time).sum()\n    score = x_t_sum.mean() / x_t_sum.std()\n\n    return 'sigma_score', score, True\n\nclass model():\n    \"\"\"this is a baseline lightLGB model with simple features\n\n    this class is for a model (that can also be\n    a combination of bagged models)\n    The commonality of the bagged models is that\n    they share the feature generation\n    \"\"\"\n\n    def __init__(self, name):\n        self.name             = name\n        self.type             = lgb.Booster\n        self.model1 = None\n        self.model2 = None\n        self.model3 = None\n        self.model4 = None\n        self.model5 = None\n        self.model6 = None\n        self.training_results = None\n        print(\"\\ninit model {}\".format(self.name))\n        sys.path.insert(0, '../') # this is for imports from /kernels\n\n    def _preprocess(self, market_data):\n        \"\"\"optional data preprocessing\"\"\"\n        try:\n            market_data = market_data.loc[market_data['time']>=date(2010, 1, 1)]\n        except TypeError: # if 'time' is a string value\n            print(\"[_generate_features] 'time' is of type str and not datetime\")\n            if not market_data.loc[market_data['time']>=\"2010\"].empty:\n                # if dates are before 2010 means dataset is for testing\n                market_data = market_data.loc[market_data['time']>=\"2010\"]\n        assert market_data.empty == False\n        return market_data\n\n\n    def _generate_features(self, market_data, news_data, verbose=False, normalize=True, normalize_vals=[None], output_len = None):\n        \"\"\"\n        GENERAL:\n        given the original market_data and news_data\n        generate new features, doesn't change original data.\n        NOTE: data cleaning and preprocessing is not here,\n        here is only feats engineering\n\n        MODEL SPECIFIC:\n        as as a baseline for decision trees model we add\n        features that are the most popular among public\n        kernels on Kaggle:\n\n        - [36] short-term lagged features on returns\n        - has been removed (cant pass tests) [6]  long-term moving averages\n        - [1]  day of the week\n\n        Args:\n            [market_train_df, news_train_df]: pandas.DataFrame\n            normalize: (bool)\n            normalize_vals: None or [maxs, mins], normalize with local vals or with given vals\n            unique_assetCodess: list(str),for mapping assetCodeT\n\n        Returns:\n            complete_features: pandas.DataFrame\n        \"\"\"\n        #from utils import progress\n        start_time = time()\n        if verbose: print(\"Starting features generation for model {}, {}\".format(self.name, ctime()))\n\n        complete_features = market_data.copy()\n\n        if 'returnsOpenNextMktres10' in complete_features.columns:\n            complete_features.drop(['returnsOpenNextMktres10'],axis=1,inplace=True)\n\n        #### [36] short-term lagged features on returns ####\n\n\n        def create_lag(df_code,n_lag=[3,7,14,],shift_size=1):\n            code = df_code['assetCode'].unique()\n\n            # how to print progress in preprocessing?\n            # progress(0, len(n_lag)*len(return_features), prefix = 'Lagged features generation:', length=50)\n            # print(\"\\rcreating lags for {}\".format(code))\n            for _feature, col in enumerate(return_features):\n                for _lag, window in enumerate(n_lag):\n                    rolled = df_code[col].shift(shift_size).rolling(window=window)\n                    lag_mean = rolled.mean()\n                    lag_max = rolled.max()\n                    lag_min = rolled.min()\n                    lag_std = rolled.std()\n                    df_code['lag_%s_%s_mean'%(window,col)] = lag_mean\n                    df_code['lag_%s_%s_max'%(window,col)] = lag_max\n                    df_code['lag_%s_%s_min'%(window,col)] = lag_min\n        #             df_code['%s_lag_%s_std'%(col,window)] = lag_std\n                    #progress(_feature * len(n_lag) + _lag, len(n_lag) * len(return_features),\n                    #prefix = 'Lagged features generation:', length = 50)\n            return df_code.fillna(-1)\n\n        def generate_lag_features(df,n_lag = [3,7,14]):\n            features = ['time', 'assetCode', 'assetName', 'volume', 'close', 'open',\n               'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n               'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n               'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n               'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n               'returnsOpenNextMktres10', 'universe']\n\n            assetCodes = df['assetCode'].unique()\n            print(assetCodes)\n            all_df = []\n            df_codes = df.groupby('assetCode')\n            df_codes = [df_code[1][['time','assetCode']+return_features] for df_code in df_codes]\n            print('total %s df'%len(df_codes))\n\n            pool = Pool(4)\n            all_df = pool.map(create_lag, df_codes)\n\n            new_df = pd.concat(all_df)\n            new_df.drop(return_features,axis=1,inplace=True)\n            pool.close()\n\n            # for the next two lines\n            # https://stackoverflow.com/questions/49888485/pathos-multiprocessings-pool-appears-to-be-nonlocal\n            pool.terminate()\n            pool.restart()\n\n            return new_df\n\n        return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\n        n_lag = [3,7,14]\n        new_df = generate_lag_features(complete_features,n_lag=n_lag)\n        new_df['time'] = pd.to_datetime(new_df['time'])\n        complete_features['time'] = pd.to_datetime(complete_features['time'])\n        complete_features = pd.merge(complete_features,new_df,how='left',on=['time','assetCode'])\n        self.max_lag = max(n_lag)\n\n        if output_len is not None:\n            complete_features = complete_features[-output_len:]\n\n        complete_features = self._clean_data(complete_features)\n\n        #### [1]  generate labels encoding for assetCode ####\n\n        def data_prep(market_train, unique_assetCodes):\n            \"\"\"procedure from https://www.kaggle.com/guowenrui/sigma-eda-versionnew\n            Args:\n                market_train: df\n                unique_assetCodes: market_train['assetCode'].unique() this should be standard map!\n            \"\"\"\n            lbl = {k: v for v, k in enumerate(unique_assetCodes)}\n            market_train['assetCodeT'] = market_train['assetCode'].map(lbl) # this might get an error because mapping doesn't exist (read below)\n\n            # so the mapping has a bug, I should always use the same map and not every time a different map\n            # I might get assetCode not in the map, in that case need to handle exception putting (len + 1) as mapping value\n\n\n            market_train = market_train.dropna(axis=0)\n            return market_train\n\n        complete_features = data_prep(complete_features, complete_features['assetCode'].unique())\n\n        #### drop columns ####\n\n        fcol = [c for c in complete_features if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences',\n                                                         'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider',\n                                                                                                      'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n        complete_features = complete_features[fcol]\n\n\n        #### normalization of input ####\n\n        if normalize:\n            if len(normalize_vals) == 1:\n                mins = np.min(complete_features, axis=0)\n                maxs = np.max(complete_features, axis=0)\n                self.mins = mins #saved for prediction phase\n                self.maxs = maxs #saved for prediction phase\n                rng = maxs - mins\n                complete_features = 1 - ((maxs - complete_features) / rng)\n            else:\n                mins = normalize_vals[1]\n                maxs = normalize_vals[0]\n                rng = maxs - mins\n                complete_features = 1 - ((maxs - complete_features) / rng)\n\n\n        if verbose: print(\"Finished features generation for model {}, TIME {}\".format(self.name, time()-start_time))\n        return complete_features\n\n    def _generate_target(self, Y):\n        \"\"\"\n        given Y generate binary labels\n        returns:\n            up, r : (binary labels), (returns)\n        \"\"\"\n        binary_labels = Y >= 0\n        return binary_labels.astype(int).values, Y.values\n\n    def train(self, X, Y, verbose=False, normalize=True, normalize_vals=[None]):\n        \"\"\"\n        GENERAL:\n        basic method to train a model with given data\n        model will be inside self.model after training\n\n        MODEL SPECIFIC:\n\n        - sklearn random split\n        - universe filter on validation\n        - binary classification\n            need to put 'metric':'None' in parameters\n        - target is Y > 0\n\n        Args:\n            X: [market_train_df, news_train_df]\n            Y: [target]\n            verbose: (bool)\n        Returns:\n            (optional) training_results\n        \"\"\"\n        start_time = time()\n        if verbose: print(\"Starting training for model {}, {}\".format(self.name, ctime()))\n\n        time_reference = X[0]['time'] #time is dropped in preprocessing, but is needed later for metrics eval\n        universe_reference = X[0]['universe']\n\n        X = self._generate_features(X[0], X[1], verbose=verbose, normalize=normalize, normalize_vals=normalize_vals)\n        binary_Y, Y = self._generate_target(Y)\n\n        try:\n            assert X.shape[0] == binary_Y.shape[0] == Y.shape[0]\n        except AssertionError:\n            import pdb;pdb.set_trace()\n            pass\n\n        from sklearn import model_selection\n        X_train, X_val,\\\n        binary_Y_train, binary_Y_val,\\\n        Y_train, Y_val,\\\n        universe_train, universe_val,\\\n        time_train, time_val = model_selection.train_test_split(\n                X,\n                binary_Y,\n                Y,\n                universe_reference.values,\n                time_reference, test_size=0.25, random_state=99)\n\n        assert X_train.shape[0] == Y_train.shape[0] == binary_Y_train.shape[0]\n\n        if verbose: print(\"X_train shape {}\".format(X_train.shape))\n        if verbose: print(\"X_val shape {}\".format(X_val.shape))\n        assert X_train.shape[0] != X_val.shape[0]\n        assert X_train.shape[1] == X_val.shape[1]\n\n        # train parameters prearation\n        train_cols = X.columns.tolist()\n        assert 'returnsOpenNextMktres10' not in train_cols\n        train_data = lgb.Dataset(X.values, binary_Y, feature_name=train_cols)\n        test_data = lgb.Dataset(X_val.values, binary_Y_val, feature_name=train_cols)\n\n        x_1 = [0.19000424246380565, 2452, 212, 328, 202]\n        x_2 = [0.19016805202090095, 2583, 213, 312, 220]\n        x_3 = [0.19564034613157152, 2452, 210, 160, 219]\n        x_4 = [0.19016805202090095, 2500, 213, 150, 202]\n        x_5 = [0.19000424246380565, 2600, 215, 140, 220]\n        x_6 = [0.19000424246380565, 2652, 216, 152, 202]\n\n        params_1 = {\n                'task': 'train',\n                'boosting_type': 'gbdt',\n                'objective': 'binary',\n                'learning_rate': x_1[0],\n                'num_leaves': x_1[1],\n                'min_data_in_leaf': x_1[2],\n                'num_iteration': 239+10,\n                'max_bin': x_1[4],\n                'verbose': 1\n            }\n\n        params_2 = {\n                'task': 'train',\n                'boosting_type': 'gbdt',\n                'objective': 'binary',\n                'learning_rate': x_2[0],\n                'num_leaves': x_2[1],\n                'min_data_in_leaf': x_2[2],\n                'num_iteration': 172+10,\n                'max_bin': x_2[4],\n                'verbose': 1\n            }\n\n\n        params_3 = {\n                'task': 'train',\n                'boosting_type': 'gbdt',\n                'objective': 'binary',\n                'learning_rate': x_3[0],\n                'num_leaves': x_3[1],\n                'min_data_in_leaf': x_3[2],\n                'num_iteration': x_3[3]+10,\n                'max_bin': x_3[4],\n                'verbose': 1\n            }\n\n        params_4 = {\n                'task': 'train',\n                'boosting_type': 'gbdt',\n                'objective': 'binary',\n                'learning_rate': x_4[0],\n                'num_leaves': x_4[1],\n                'min_data_in_leaf': x_4[2],\n                'num_iteration': x_4[3]+10,\n                'max_bin': x_4[4],\n                'verbose': 1\n            }\n\n        params_5 = {\n                'task': 'train',\n                'boosting_type': 'gbdt',#dart\n                'objective': 'binary',\n                'learning_rate': x_5[0],\n                'num_leaves': x_5[1],\n                'min_data_in_leaf': x_5[2],\n                'num_iteration': x_5[3]+10,\n                'max_bin': x_5[4],\n                'verbose': 1\n            }\n\n        params_6 = {\n                'task': 'train',\n                'boosting_type': 'gbdt',\n                'objective': 'binary',\n                'learning_rate': x_6[0],\n                'num_leaves': x_6[1],\n                'min_data_in_leaf': x_6[2],\n                'num_iteration': x_6[3]+10,\n                'max_bin': x_6[4],\n                'verbose': 1\n            }\n\n        training_results = {}\n        self.model1 = lgb.train(params_1,\n                train_data,\n                num_boost_round=100,\n                valid_sets=(test_data, train_data),\n                valid_names=('valid','train'),\n                early_stopping_rounds=5,\n                verbose_eval=1,\n                evals_result=training_results)\n\n        self.model2 = lgb.train(params_2,\n                train_data,\n                valid_sets=(test_data, train_data),\n                valid_names=('valid','train'),\n                num_boost_round=100,\n                verbose_eval=1,\n                early_stopping_rounds=5,\n                evals_result=training_results)\n\n\n        self.model3 = lgb.train(params_3,\n                train_data,\n                num_boost_round=100,\n                valid_sets=test_data,\n                early_stopping_rounds=5,\n        #         fobj=exp_loss,\n                )\n\n        self.model4 = lgb.train(params_4,\n                train_data,\n                num_boost_round=100,\n                valid_sets=test_data,\n                early_stopping_rounds=5,\n        #         fobj=exp_loss,\n                )\n\n        self.model5 = lgb.train(params_5,\n                train_data,\n                num_boost_round=100,\n                valid_sets=test_data,\n                early_stopping_rounds=5,\n        #         fobj=exp_loss,\n                )\n\n\n        self.model6 = lgb.train(params_6,\n                train_data,\n                num_boost_round=100,\n                valid_sets=test_data,\n                early_stopping_rounds=10,\n        #         fobj=exp_loss,\n                )\n\n        del X, X_train, X_val\n\n        if verbose: print(\"Finished training for model {}, TIME {}\".format(self.name, time()-start_time))\n        \n        try:\n            self._save()\n        except:\n            print(\"[train] WARNING: couldn't save the model!\")\n        self.training_results = training_results\n        return training_results\n\n    def predict(self, X, verbose=False, do_shap=False, normalize=True, normalize_vals = [None]):\n        \"\"\"\n        given a block of X features gives prediction for everyrow+\".pkl\"\n\n        Args:\n            X: [market_train_df, news_train_df]\n            shap: perform shap analysis\n            normalize: (bool)\n            normalize_vals: recommmended self.maxs, self.mins\n        Returns:\n            y: pandas.Series\n        \"\"\"\n        start_time = time()\n        if verbose: print(\"Starting prediction for model {}, {}\".format(self.name, ctime()))\n        if self.model1 is None or self.model2 is None:\n            raise \"Error: model is not trained!\"\n\n        X_test = self._generate_features(X[0], X[1], verbose=verbose, normalize=normalize, normalize_vals=normalize_vals)\n        if verbose: print(\"X_test shape {}\".format(X_test.shape))\n        preds= []\n        preds.append(self.model1.predict(X_test))\n        preds.append(self.model2.predict(X_test))\n        preds.append(self.model3.predict(X_test))\n        preds.append(self.model4.predict(X_test))\n        preds.append(self.model5.predict(X_test))\n        preds.append(self.model6.predict(X_test))\n        y_test = self._postprocess(preds)\n\n        if do_shap:\n            #import pdb;pdb.set_trace()\n            print(\"printing shap analysis..\")\n            explainer = shap.TreeExplainer(self.model1)\n            shap_values = explainer.shap_values(X_test)\n            shap.summary_plot(shap_values, X_test)\n\n\n        if verbose: print(\"Finished prediction for model {}, TIME {}\".format(self.name, time()-start_time))\n        return y_test\n\n    def predict_rolling(self, historical_df, market_obs_df, verbose=False, normalize=True, normalize_vals=[None]):\n        \"\"\"\n        predict features from X, uses historical for (lagged) feature generation\n        to be used with rolling prediciton structure from competition\n\n        Args:\n            historical_df: [market_train_df, news_train_df]\n            market_obs_df: from rolling prediction generator\n        \"\"\"\n        start_time = time()\n        if verbose: print(\"Starting rolled prediction for model {}, {}\".format(self.name, ctime()))\n        if self.model1 is None or self.model2 is None:\n            raise \"Error: model is not trained!\"\n\n        X_test = self._generate_features(historical_df[0], historical_df[1], verbose=verbose, normalize=normalize, normalize_vals=normalize_vals, output_len=len(market_obs_df))\n        X_test.reset_index(drop=True,inplace=True)\n        if verbose: print(\"X_test shape {}\".format(X_test.shape))\n        preds= []\n        preds.append(self.model1.predict(X_test))\n        preds.append(self.model2.predict(X_test))\n        preds.append(self.model3.predict(X_test))\n        preds.append(self.model4.predict(X_test))\n        preds.append(self.model5.predict(X_test))\n        preds.append(self.model6.predict(X_test))\n        y_test = self._postprocess(preds)\n\n        if verbose: print(\"Finished rolled prediction for model {}, TIME {}\".format(self.name, time()-start_time))\n        return y_test\n\n    def inspect(self, X):\n        \"\"\"\n        visualize and examine the training of the model\n        Args:\n            X: for the shap values\n\n        MODEL SPECIFIC:\n        plots training results and feature importance\n        \"\"\"\n        if not self.training_results:\n            print(\"Error: No training results available\")\n        else:\n            print(\"printing training results..\")\n            for _label, key in self.training_results.items():\n                for label, result in key.items():\n                    plt.plot(result,label=_label+\" \"+label)\n            plt.title(\"Training results\")\n            plt.legend()\n            plt.show()\n\n        if not self.model1:\n            print(\"Error: No model available\")\n        else:\n            print(\"printing feature importance..\")\n            f=lgb.plot_importance(self.model1)\n            f.figure.set_size_inches(10, 30)\n            plt.show()\n\n    def _postprocess(self, predictions):\n        \"\"\"\n        post processing of predictions\n\n        Args:\n            predictions: list(np.array) might be from\n                different models\n        Return:\n            predictions: np.array\n\n        MODEL SPECIFIC:\n        the postprocessing is needed to ensemble bagged\n        models and to map prediction interval from [0, 1]\n        to [-1, 1]\n        \"\"\"\n        y_test = sum(predictions)/len(predictions)\n        y_test = (y_test-y_test.min())/(y_test.max()-y_test.min())\n        y_test = y_test * 2 - 1\n        return y_test\n\n    def _clean_data(self, data):\n        \"\"\"\n        originally from function mis_impute in\n        https://www.kaggle.com/guowenrui/sigma-eda-versionnew\n\n        Args:\n            data: pd.DataFrame\n        returns:\n            cleaned data (not in place)\n        \"\"\"\n        for i in data.columns:\n            if data[i].dtype == \"object\":\n                    data[i] = data[i].fillna(\"other\")\n            elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n                    data[i] = data[i].fillna(data[i].mean())\n                    # I am just filling the mean of all stocks together?\n                    # should fill with the mean of the singular stock\n            else:\n                    pass\n        return data\n\n    def _save(self):\n        \"\"\"\n        save models to memory into pickle/self.name\n        \"\"\"\n        to_save = [self.model1, self.model2, self.model3, self.model4, self.model5, self.model6]\n        if not all(to_save):\n            print(\"[_save] Error: not all models are trained\")\n            print(to_save)\n        else:\n            save_name = os.path.join(\"../pickle\",self.name+\"_\")\n            with open(save_name,\"wb\") as f:\n                pk.dump(to_save, f)\n                print(\"[_save] saved models to \"+save_name)\n\n    def _load(self):\n        \"\"\"\n        load models to memory from pickle/self.name\n        \"\"\"\n        save_name = os.path.join(\"../pickle\",self.name)+\".pkl\"\n        with open(save_name,\"rb\") as f:\n            models = pk.load(f)\n        self.model1 = models[0]\n        self.model2 = models[1]\n        self.model3 = models[2]\n        self.model4 = models[3]\n        self.model5 = models[4]\n        self.model6 = models[5]\n        print(\"[_load] models loaded succesfully\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "77f6f83f36a4662b59481bf84ecd3737c9a4869b"
      },
      "cell_type": "code",
      "source": "from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1866db8876081badb3ee4f6eed273d4c9884ab3a"
      },
      "cell_type": "code",
      "source": "(market_train_df, news_train_df) = env.get_training_data()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62646067f09f500ea211252ad880ce03d750c996"
      },
      "cell_type": "code",
      "source": "market_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']\nmodel = model('lgbm_71_leak')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abd39f5899ca8e5b2fb336a29c90ff1231633d59"
      },
      "cell_type": "code",
      "source": "target = market_train_df.returnsOpenNextMktres10\nmarket_train_df.drop('returnsOpenNextMktres10', axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f088c61f7032600794c768d359fa96361842382"
      },
      "cell_type": "code",
      "source": "model.train([market_train_df, news_train_df], target, verbose=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9d7725faa3903c57f0272be6ff8dcc2855c8ec7"
      },
      "cell_type": "code",
      "source": "max_values, min_values, max_lag = model.maxs, model.mins, model.max_lag # values used for normalization during predictions",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c174bb863a6fadbc0f3dedd8a2fb869071496e40"
      },
      "cell_type": "code",
      "source": "days = env.get_prediction_days()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5668d80938d2649a44d2353bbb1be9a817ed4a5b"
      },
      "cell_type": "code",
      "source": "\"\"\"locals required\nmodel: instance of model class defined above\nmax_values, min_values: (pd.DataFrame)\nmax_lag: (int)\n\"\"\"\nfrom time import time\nn_days, prep_time, prediction_time, packaging_time = 0, 0, 0, 0\ntotal_market_obs_df = []\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0): print(n_days,end=' ')\n    t = time()\n    market_obs_df['time'] = market_obs_df['time'].dt.date\n\n    total_market_obs_df.append(market_obs_df)\n    if len(total_market_obs_df) == 1:\n        history_df = total_market_obs_df[0]\n    else:\n        history_df = pd.concat(total_market_obs_df[-(max_lag + 1):])\n        \n    confidence = model.predict_rolling([history_df, None], market_obs_df, verbose=True, normalize=True, normalize_vals = [max_values, min_values])      \n        \n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time() - t",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93f2f6fd66ce44cca2619482872939e040e66d98"
      },
      "cell_type": "code",
      "source": "predictions_template_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "935637627a6a9963da3fbe1ff1d2f78b4a77ed59"
      },
      "cell_type": "code",
      "source": "env.write_submission_file()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d4abc981cc689e6855f55fee918a42a5e4d872d"
      },
      "cell_type": "code",
      "source": "# We've got a submission file!\nimport os\nprint([filename for filename in os.listdir('.') if '.csv' in filename])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03aa2f4ae07078b969017bba7f392c0d80de508f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "626f2808651778d98ffc2479c8ce77c6ad1e5447"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e87730ce59e4190a6719d206c8b4d3211c38eba4"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d3f3f266fbc68fa8cbfe3f2c7b152055945b2a7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60fa8039ffa1b1b0dc86ee37f20718b372853e3b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16a97b16b33c754cae41f88f07cb20f2710b7940"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b31dc64c6d0ea417c532a0dbf84f8c6d6addfbc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1b514363c9b34621af9cd8dc4248c9540d430aa"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe5cf48610b7a476dfd17e828ea145a19404139e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9950efe8015fdda7a871e1fb8a2183e583a2c6c"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "63f362f8a27d603072132eab37ae1c39b59c7334"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95491d0ab17e0e173cc010d446220fed664785c4"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3cd2dabc5a2b9f591ae840a7d9567d0a685543ee"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c67eb651a26266bebcfc32efa0ebc6f201de678"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "509bdba20c9142d21958550491d9599c02e2491b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}